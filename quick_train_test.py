#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿè¨“ç·´æ¸¬è©¦ - è·³éè¤‡é›œé è™•ç†
ç›´æ¥æ¸¬è©¦è¨“ç·´æ˜¯å¦èƒ½æ­£å¸¸é€²è¡Œ
"""

import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import os
from datetime import datetime

# æª¢æŸ¥GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ ä½¿ç”¨è¨­å‚™: {device}")

# ç°¡å–®çš„ GRU æ¨¡å‹
class SimpleSignLanguageGRU(nn.Module):
    def __init__(self, input_size=163, hidden_size=64, num_classes=20, num_layers=1):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.gru = nn.GRU(input_size, hidden_size, num_layers, 
                          batch_first=True, bidirectional=True)
        self.dropout = nn.Dropout(0.2)
        self.fc = nn.Linear(hidden_size * 2, num_classes)  # *2 for bidirectional
        
    def forward(self, x):
        # x shape: (batch, seq_len, features)
        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)
        
        out, _ = self.gru(x, h0)
        out = self.dropout(out[:, -1, :])  # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥
        out = self.fc(out)
        return out

def create_fake_data(num_samples=1000, seq_length=20, input_size=163, num_classes=20):
    """å‰µå»ºå‡æ•¸æ“šç”¨æ–¼æ¸¬è©¦"""
    print(f"å‰µå»ºæ¸¬è©¦æ•¸æ“š: {num_samples} æ¨£æœ¬, åºåˆ—é•·åº¦ {seq_length}")
    
    # ç”Ÿæˆéš¨æ©Ÿåºåˆ—æ•¸æ“š
    X = torch.randn(num_samples, seq_length, input_size)
    y = torch.randint(0, num_classes, (num_samples,))
    
    return X, y

def train_quick_test():
    """å¿«é€Ÿè¨“ç·´æ¸¬è©¦"""
    print("\nğŸ¯ é–‹å§‹å¿«é€Ÿè¨“ç·´æ¸¬è©¦")
    print("=" * 50)
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    X, y = create_fake_data(num_samples=500, seq_length=20)
    
    # åˆ†å‰²è¨“ç·´æ¸¬è©¦é›†
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"è¨“ç·´é›†: {X_train.shape}, æ¸¬è©¦é›†: {X_test.shape}")
    
    # ç§»åˆ°GPU
    X_train = X_train.to(device)
    y_train = y_train.to(device)
    X_test = X_test.to(device)
    y_test = y_test.to(device)
    
    # å‰µå»ºæ¨¡å‹
    model = SimpleSignLanguageGRU(
        input_size=163,
        hidden_size=64,
        num_classes=20,
        num_layers=1
    ).to(device)
    
    print(f"æ¨¡å‹åƒæ•¸æ•¸é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨
    from torch.utils.data import TensorDataset, DataLoader
    
    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
    
    # è¨“ç·´å¾ªç’°
    model.train()
    print("\né–‹å§‹è¨“ç·´...")
    
    for epoch in range(5):  # åªè¨“ç·´5å€‹epochæ¸¬è©¦
        epoch_loss = 0
        num_batches = 0
        
        for batch_idx, (batch_X, batch_y) in enumerate(train_loader):
            # å‰å‘å‚³æ’­
            optimizer.zero_grad()
            outputs = model(batch_X)
            loss = criterion(outputs, batch_y)
            
            # åå‘å‚³æ’­
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            num_batches += 1
            
            # æ¯10å€‹batché¡¯ç¤ºé€²åº¦
            if batch_idx % 10 == 0:
                print(f"  Epoch {epoch+1}/5, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}")
        
        avg_loss = epoch_loss / num_batches
        print(f"Epoch {epoch+1}/5 å®Œæˆ, å¹³å‡æå¤±: {avg_loss:.4f}")
    
    # æ¸¬è©¦
    model.eval()
    with torch.no_grad():
        test_outputs = model(X_test)
        test_loss = criterion(test_outputs, y_test)
        _, predicted = torch.max(test_outputs.data, 1)
        accuracy = (predicted == y_test).sum().item() / y_test.size(0)
        
        print(f"\nâœ… æ¸¬è©¦å®Œæˆ")
        print(f"æ¸¬è©¦æå¤±: {test_loss.item():.4f}")
        print(f"æ¸¬è©¦æº–ç¢ºç‡: {accuracy:.4f}")
    
    print(f"\nğŸ‰ å¿«é€Ÿè¨“ç·´æ¸¬è©¦æˆåŠŸå®Œæˆï¼")
    return True

def test_real_data_loading():
    """æ¸¬è©¦è¼‰å…¥çœŸå¯¦æ•¸æ“šçš„ç¬¬ä¸€å€‹æ–‡ä»¶"""
    print("\nğŸ“ æ¸¬è©¦è¼‰å…¥çœŸå¯¦æ•¸æ“š")
    print("=" * 50)
    
    try:
        # æ‰¾ç¬¬ä¸€å€‹CSVæ–‡ä»¶
        csv_files = [f for f in os.listdir('dataset') if f.startswith('sign_language') and f.endswith('.csv')]
        if not csv_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ°CSVæ–‡ä»¶")
            return False
        
        first_file = os.path.join('dataset', csv_files[0])
        print(f"è¼‰å…¥æ–‡ä»¶: {first_file}")
        
        # è¼‰å…¥ç¬¬ä¸€å€‹æ–‡ä»¶
        df = pd.read_csv(first_file)
        print(f"æ–‡ä»¶å½¢ç‹€: {df.shape}")
        print(f"é¡åˆ¥: {df['sign_language'].unique()[:5]}...")  # é¡¯ç¤ºå‰5å€‹é¡åˆ¥
        
        # æª¢æŸ¥ç‰¹å¾µæ¬„ä½
        feature_cols = [col for col in df.columns if col not in ['sign_language', 'source_video', 'frame']]
        print(f"ç‰¹å¾µæ¬„ä½æ•¸: {len(feature_cols)}")
        
        # æª¢æŸ¥ç¼ºå¤±å€¼
        missing_counts = df[feature_cols].isnull().sum().sum()
        print(f"ç¸½ç¼ºå¤±å€¼: {missing_counts}")
        
        print("âœ… çœŸå¯¦æ•¸æ“šè¼‰å…¥æ¸¬è©¦æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âŒ çœŸå¯¦æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        return False

def main():
    print("ğŸš€ å¿«é€Ÿè¨“ç·´è¨ºæ–·å·¥å…·")
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # æ¸¬è©¦GPU
    if torch.cuda.is_available():
        print(f"âœ… GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"GPUè¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âŒ GPUä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨CPU")
    
    # æ¸¬è©¦çœŸå¯¦æ•¸æ“šè¼‰å…¥
    if not test_real_data_loading():
        print("è·³éçœŸå¯¦æ•¸æ“šæ¸¬è©¦ï¼Œä½¿ç”¨å‡æ•¸æ“š")
    
    # åŸ·è¡Œå¿«é€Ÿè¨“ç·´æ¸¬è©¦
    try:
        train_quick_test()
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å®Œæˆï¼è¨“ç·´ç’°å¢ƒæ­£å¸¸å·¥ä½œ")
    except Exception as e:
        print(f"\nâŒ è¨“ç·´æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

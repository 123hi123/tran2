#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¨“ç·´å•é¡Œè¨ºæ–·å·¥å…·
æª¢æŸ¥è¨“ç·´å¡ä½çš„åŸå› 
"""

import torch
import pandas as pd
import numpy as np
import os
import sys
import time
from datetime import datetime

def check_environment():
    """æª¢æŸ¥ç’°å¢ƒç‹€æ…‹"""
    print("ğŸ” ç’°å¢ƒè¨ºæ–·")
    print("=" * 50)
    
    # PyTorch ç‰ˆæœ¬
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # CUDA ç‹€æ…‹
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨: {torch.version.cuda}")
        print(f"GPUè¨­å‚™: {torch.cuda.get_device_name(0)}")
        print(f"GPUè¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    else:
        print("âŒ CUDAä¸å¯ç”¨ - å°‡ä½¿ç”¨CPU (éå¸¸æ…¢)")
    
    print()

def check_data():
    """æª¢æŸ¥æ•¸æ“šç‹€æ…‹"""
    print("ğŸ“ æ•¸æ“šæª¢æŸ¥")
    print("=" * 50)
    
    # æª¢æŸ¥æ•¸æ“šè³‡æ–™å¤¾
    if not os.path.exists('dataset'):
        print("âŒ dataset è³‡æ–™å¤¾ä¸å­˜åœ¨")
        return False
    
    # æª¢æŸ¥CSVæ–‡ä»¶
    csv_files = [f for f in os.listdir('dataset') if f.startswith('sign_language') and f.endswith('.csv')]
    print(f"æ‰¾åˆ° {len(csv_files)} å€‹CSVæ–‡ä»¶")
    
    if len(csv_files) == 0:
        print("âŒ æ²’æœ‰æ‰¾åˆ°æ•¸æ“šæ–‡ä»¶")
        return False
    
    # æª¢æŸ¥ç¬¬ä¸€å€‹æ–‡ä»¶
    try:
        first_file = os.path.join('dataset', csv_files[0])
        df = pd.read_csv(first_file)
        print(f"âœ… æ¨£æœ¬æ–‡ä»¶: {csv_files[0]}")
        print(f"   å½¢ç‹€: {df.shape}")
        print(f"   æ¬„ä½: {list(df.columns)[:5]}...")
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_columns = ['sign_language']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            print(f"âŒ ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
            return False
        
        return True
    except Exception as e:
        print(f"âŒ è®€å–æ•¸æ“šæ–‡ä»¶å¤±æ•—: {e}")
        return False

def test_simple_training():
    """æ¸¬è©¦ç°¡å–®çš„è¨“ç·´æ­¥é©Ÿ"""
    print("ğŸš€ ç°¡å–®è¨“ç·´æ¸¬è©¦")
    print("=" * 50)
    
    try:
        # å‰µå»ºç°¡å–®çš„å‡æ•¸æ“š
        print("å‰µå»ºæ¸¬è©¦æ•¸æ“š...")
        batch_size = 4  # æ¸›å°æ‰¹æ¬¡å¤§å°
        seq_length = 10
        input_size = 163
        num_classes = 3
        
        # å‡æ•¸æ“š
        X = torch.randn(batch_size, seq_length, input_size)
        y = torch.randint(0, num_classes, (batch_size,))
        
        # æª¢æŸ¥è¨­å‚™
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        X = X.to(device)
        y = y.to(device)
        
        # ç°¡å–®æ¨¡å‹
        from torch import nn
        
        class SimpleGRU(nn.Module):
            def __init__(self, input_size, hidden_size, num_classes):
                super().__init__()
                self.gru = nn.GRU(input_size, hidden_size, batch_first=True)
                self.fc = nn.Linear(hidden_size, num_classes)
                
            def forward(self, x):
                _, h = self.gru(x)
                return self.fc(h[-1])
        
        print("å‰µå»ºæ¨¡å‹...")
        model = SimpleGRU(input_size, 32, num_classes).to(device)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        
        # æ¸¬è©¦ä¸€å€‹è¨“ç·´æ­¥é©Ÿ
        print("åŸ·è¡Œæ¸¬è©¦è¨“ç·´æ­¥é©Ÿ...")
        start_time = time.time()
        
        model.train()
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        
        end_time = time.time()
        
        print(f"âœ… è¨“ç·´æ­¥é©ŸæˆåŠŸ")
        print(f"   æå¤±: {loss.item():.4f}")
        print(f"   æ™‚é–“: {end_time - start_time:.2f} ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¨“ç·´æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_data_loading():
    """æ¸¬è©¦æ•¸æ“šè¼‰å…¥"""
    print("ğŸ“Š æ•¸æ“šè¼‰å…¥æ¸¬è©¦")
    print("=" * 50)
    
    try:
        # å˜—è©¦è¼‰å…¥å¯¦éš›æ•¸æ“š
        from src.data_preprocessing import DataPreprocessor
        
        print("åˆå§‹åŒ–æ•¸æ“šé è™•ç†å™¨...")
        preprocessor = DataPreprocessor()
        
        print("è¼‰å…¥æ•¸æ“š...")
        start_time = time.time()
        X, y = preprocessor.load_and_preprocess()
        end_time = time.time()
        
        print(f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ")
        print(f"   Xå½¢ç‹€: {X.shape}")
        print(f"   yå½¢ç‹€: {y.shape}")
        print(f"   è¼‰å…¥æ™‚é–“: {end_time - start_time:.2f} ç§’")
        print(f"   é¡åˆ¥æ•¸: {len(np.unique(y))}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_memory():
    """æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨"""
    print("ğŸ’¾ è¨˜æ†¶é«”æª¢æŸ¥")
    print("=" * 50)
    
    try:
        import psutil
        
        # ç³»çµ±è¨˜æ†¶é«”
        memory = psutil.virtual_memory()
        print(f"ç³»çµ±è¨˜æ†¶é«”: {memory.total / 1024**3:.1f} GB")
        print(f"å¯ç”¨è¨˜æ†¶é«”: {memory.available / 1024**3:.1f} GB")
        print(f"ä½¿ç”¨ç‡: {memory.percent:.1f}%")
        
        # GPU è¨˜æ†¶é«”
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            gpu_allocated = torch.cuda.memory_allocated(0)
            gpu_cached = torch.cuda.memory_reserved(0)
            
            print(f"GPUç¸½è¨˜æ†¶é«”: {gpu_memory / 1024**3:.1f} GB")
            print(f"GPUå·²åˆ†é…: {gpu_allocated / 1024**3:.3f} GB")
            print(f"GPUå¿«å–: {gpu_cached / 1024**3:.3f} GB")
        
    except ImportError:
        print("psutil æœªå®‰è£ï¼Œç„¡æ³•æª¢æŸ¥ç³»çµ±è¨˜æ†¶é«”")
    except Exception as e:
        print(f"è¨˜æ†¶é«”æª¢æŸ¥å¤±æ•—: {e}")

def main():
    print(f"ğŸ”§ è¨“ç·´å•é¡Œè¨ºæ–·å·¥å…·")
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    print()
    
    # åŸ·è¡Œæ‰€æœ‰æª¢æŸ¥
    check_environment()
    
    if not check_data():
        print("âŒ æ•¸æ“šæª¢æŸ¥å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒ")
        return
    
    check_memory()
    
    if not test_simple_training():
        print("âŒ ç°¡å–®è¨“ç·´æ¸¬è©¦å¤±æ•—")
        return
    
    if not test_data_loading():
        print("âŒ æ•¸æ“šè¼‰å…¥æ¸¬è©¦å¤±æ•—")
        return
    
    print()
    print("ğŸ‰ æ‰€æœ‰è¨ºæ–·å®Œæˆ")
    print("=" * 60)
    print("ğŸ’¡ å»ºè­°:")
    print("1. å¦‚æœCUDAä¸å¯ç”¨ï¼Œè¨“ç·´æœƒå¾ˆæ…¢ï¼Œå»ºè­°ä¿®å¾©GPUå•é¡Œ")
    print("2. å¦‚æœè¨˜æ†¶é«”ä¸è¶³ï¼Œå˜—è©¦æ¸›å°batch_size")
    print("3. å¦‚æœæ•¸æ“šè¼‰å…¥æ…¢ï¼Œæª¢æŸ¥ç¡¬ç¢Ÿç©ºé–“å’Œæª”æ¡ˆå®Œæ•´æ€§")

if __name__ == "__main__":
    main()

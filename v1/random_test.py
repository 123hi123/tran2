"""
éš¨æ©Ÿå‹•ä½œæ¸¬è©¦å™¨ - åŸºæ–¼çœŸå¯¦æ¸¬è©¦è…³æœ¬é‚è¼¯
éš¨æ©Ÿé¸æ“‡ä¸€å€‹æ‰‹èªå‹•ä½œï¼Œæ¸¬è©¦æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¢ºé æ¸¬
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import os
import random
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class SignLanguageGRU(nn.Module):
    """æ‰‹èªè¾¨è­˜GRUæ¨¡å‹ï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒçš„æ¶æ§‹ï¼‰"""
    
    def __init__(self, input_size, hidden_size=128, num_layers=2, num_classes=10, dropout=0.3):
        super(SignLanguageGRU, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # GRUå±¤
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=True
        )
        
        # å…¨é€£æ¥å±¤
        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)  # *2 å› ç‚ºé›™å‘GRU
        self.dropout = nn.Dropout(dropout)
        self.fc2 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # x shape: (batch_size, sequence_length, input_size)
        gru_out, _ = self.gru(x)
        
        # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥çš„è¼¸å‡º
        last_output = gru_out[:, -1, :]  # (batch_size, hidden_size * 2)
        
        # é€šéå…¨é€£æ¥å±¤
        out = self.fc1(last_output)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out

class RandomActionTester:
    def __init__(self, data_folder="processed_data", model_folder="models"):
        self.data_folder = data_folder
        self.model_folder = model_folder
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.label_encoder = None
        
        print(f"ğŸ¯ éš¨æ©Ÿå‹•ä½œæ¸¬è©¦å™¨å•Ÿå‹•")
        print(f"ä½¿ç”¨è¨­å‚™: {self.device}")
    
    def load_model(self, model_path=None):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if model_path is None:
            # æ‰¾æœ€æ–°çš„æ¨¡å‹
            model_files = [f for f in os.listdir(self.model_folder) if f.endswith('.pth')]
            if not model_files:
                raise FileNotFoundError("æ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æª”æ¡ˆ")
            model_path = os.path.join(self.model_folder, sorted(model_files)[-1])
        
        print(f"è¼‰å…¥æ¨¡å‹: {model_path}")
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # è¼‰å…¥æ¨™ç±¤ç·¨ç¢¼å™¨
        encoder_path = os.path.join(self.data_folder, "label_encoder.pkl")
        self.label_encoder = joblib.load(encoder_path)
        
        # å»ºç«‹æ¨¡å‹
        model_config = checkpoint['model_config']
        self.model = SignLanguageGRU(
            input_size=model_config['input_size'],
            hidden_size=model_config['hidden_size'],
            num_layers=model_config['num_layers'],
            num_classes=model_config['num_classes']
        ).to(self.device)
        
        # è¼‰å…¥æ¨¡å‹æ¬Šé‡
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        print(f"ğŸ“Š é¡åˆ¥æ•¸é‡: {len(self.label_encoder.classes_)}")
        print(f"ğŸ·ï¸ é¡åˆ¥: {list(self.label_encoder.classes_)}")
        
        return checkpoint
    
    def load_test_data(self):
        """è¼‰å…¥æ¸¬è©¦è³‡æ–™ - èˆ‡æ¸¬è©¦è…³æœ¬å®Œå…¨ç›¸åŒ"""
        test_path = os.path.join(self.data_folder, "test_dataset.csv")
        
        if not os.path.exists(test_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¸¬è©¦è³‡æ–™é›†: {test_path}")
        
        test_data = pd.read_csv(test_path)
        print(f"ğŸ“ è¼‰å…¥æ¸¬è©¦è³‡æ–™: {test_data.shape}")
        
        if len(test_data) == 0:
            raise ValueError("æ¸¬è©¦è³‡æ–™é›†ç‚ºç©º")
        
        # è™•ç†ç¼ºå¤±å€¼ï¼ˆèˆ‡æ¸¬è©¦è…³æœ¬ä¿æŒä¸€è‡´ï¼‰
        self._preprocess_test_data(test_data)
        
        return test_data
    
    def _preprocess_test_data(self, data):
        """é è™•ç†æ¸¬è©¦æ•¸æ“šï¼Œèˆ‡æ¸¬è©¦è…³æœ¬å®Œå…¨ç›¸åŒ"""
        total_missing = data.isnull().sum().sum()
        if total_missing > 0:
            print(f"âš ï¸  æ¸¬è©¦æ•¸æ“šç™¼ç¾ {total_missing} å€‹ç¼ºå¤±å€¼ï¼Œé€²è¡Œè™•ç†...")
            
            # å˜—è©¦ä½¿ç”¨æ”¹é€²çš„è™•ç†å™¨
            try:
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(__file__)))
                from improved_missing_handler import ImprovedMissingValueProcessor
                
                processor = ImprovedMissingValueProcessor()
                processor.calculate_neutral_positions(data)
                data_processed = processor.smart_interpolation(data)
                
                # å°‡è™•ç†çµæœæ›´æ–°å›åŸæ•¸æ“š
                data.update(data_processed)
                print("âœ… æ™ºèƒ½ç¼ºå¤±å€¼è™•ç†å®Œæˆ")
                
            except ImportError:
                print("âš ï¸  ä½¿ç”¨åŸºç¤ç¼ºå¤±å€¼è™•ç†...")
                # åŸºç¤è™•ç†ï¼šå¡«å…… 0
                data.fillna(0, inplace=True)
        else:
            print("âœ… æ¸¬è©¦æ•¸æ“šæ²’æœ‰ç¼ºå¤±å€¼")
    
    def prepare_all_test_sequences(self, data, sequence_length=20):
        """æº–å‚™æ‰€æœ‰æ¸¬è©¦åºåˆ— - èˆ‡æ¸¬è©¦è…³æœ¬é‚è¼¯å®Œå…¨ç›¸åŒ"""
        # ç‰¹å¾µæ¬„ä½ï¼ˆæ’é™¤æ¨™ç±¤ç›¸é—œæ¬„ä½å’Œframeï¼Œèˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´ï¼‰
        feature_cols = [col for col in data.columns 
                       if col not in ['sign_language', 'sign_language_encoded', 'frame', 'source_video']]
        
        print(f"æ¸¬è©¦ç‰¹å¾µç¶­åº¦: {len(feature_cols)} (æ’é™¤: sign_language, sign_language_encoded, frame, source_video)")
        
        # æŒ‰é¡åˆ¥åˆ†çµ„å‰µå»ºåºåˆ—
        sequences = []
        labels = []
        class_names = []
        sequence_info = []  # æ·»åŠ åºåˆ—ä¿¡æ¯è¿½è¹¤
        
        # æŒ‰sign_languageåˆ†çµ„
        for sign_language in data['sign_language'].unique():
            class_data = data[data['sign_language'] == sign_language]
            
            # å¦‚æœè³‡æ–™é•·åº¦è¶…ésequence_lengthï¼Œå‰µå»ºæ»‘å‹•çª—å£åºåˆ—
            if len(class_data) >= sequence_length:
                for i in range(len(class_data) - sequence_length + 1):
                    seq = class_data.iloc[i:i+sequence_length][feature_cols].values
                    sequences.append(seq)
                    labels.append(class_data.iloc[i]['sign_language_encoded'])
                    class_names.append(sign_language)
                    # æ·»åŠ åºåˆ—ä¾†æºä¿¡æ¯
                    start_frame = i + 1
                    end_frame = i + sequence_length
                    sequence_info.append(f"{sign_language}_seq_{start_frame}-{end_frame}")
            else:
                # å¦‚æœè³‡æ–™ä¸è¶³ï¼Œé€²è¡Œå¡«å……
                seq_data = class_data[feature_cols].values
                if len(seq_data) < sequence_length:
                    # é‡è¤‡æœ€å¾Œä¸€å¹€ä¾†å¡«å……
                    padding_needed = sequence_length - len(seq_data)
                    last_frame = seq_data[-1:] if len(seq_data) > 0 else np.zeros((1, len(feature_cols)))
                    padding = np.repeat(last_frame, padding_needed, axis=0)
                    seq_data = np.vstack([seq_data, padding])
                
                sequences.append(seq_data)
                labels.append(class_data.iloc[0]['sign_language_encoded'])
                class_names.append(sign_language)
                sequence_info.append(f"{sign_language}_padded")
        
        sequences = np.array(sequences, dtype=np.float32)
        labels = np.array(labels, dtype=np.int64)
        
        print(f"æ¸¬è©¦åºåˆ—å½¢ç‹€: {sequences.shape}")
        print(f"æ¸¬è©¦æ¨™ç±¤å½¢ç‹€: {labels.shape}")
        
        return sequences, labels, class_names, sequence_info
    
    def predict_single_sequence(self, sequence):
        """å°å–®å€‹åºåˆ—é€²è¡Œé æ¸¬"""
        # è½‰æ›ç‚ºtensorä¸¦æ·»åŠ batchç¶­åº¦
        sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(self.device)  # (1, seq_len, features)
        
        # é æ¸¬
        with torch.no_grad():
            outputs = self.model(sequence_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(outputs, dim=1).item()
            confidence = probabilities[0, predicted_class].item()
        
        return predicted_class, confidence, probabilities[0].cpu().numpy()
    
    def run_random_test(self, num_tests=5, sequence_length=20):
        """åŸ·è¡Œéš¨æ©Ÿæ¸¬è©¦"""
        print("=" * 70)
        print("ğŸ¯ éš¨æ©Ÿå‹•ä½œé æ¸¬æ¸¬è©¦")
        print("=" * 70)
        
        # è¼‰å…¥æ¨¡å‹å’Œæ•¸æ“š
        self.load_model()
        test_data = self.load_test_data()
        
        # æº–å‚™æ‰€æœ‰æ¸¬è©¦åºåˆ—ï¼ˆä½¿ç”¨èˆ‡æ¸¬è©¦è…³æœ¬ç›¸åŒçš„é‚è¼¯ï¼‰
        X_test, y_test, class_names, sequence_info = self.prepare_all_test_sequences(test_data, sequence_length)
        
        if len(X_test) == 0:
            print("âŒ æ²’æœ‰å¯ç”¨çš„æ¸¬è©¦åºåˆ—")
            return
        
        correct_predictions = 0
        
        for test_num in range(num_tests):
            print(f"\nğŸ”„ æ¸¬è©¦ {test_num + 1}/{num_tests}")
            print("-" * 50)
            
            # éš¨æ©Ÿé¸æ“‡ä¸€å€‹åºåˆ—
            random_idx = random.randint(0, len(X_test) - 1)
            sequence = X_test[random_idx]
            true_label = y_test[random_idx]
            true_class = self.label_encoder.classes_[true_label]
            seq_info = sequence_info[random_idx]
            
            print(f"ğŸ“ åºåˆ—ç·¨è™Ÿ: {random_idx}")
            print(f"ğŸ“ åºåˆ—ä¾†æº: {seq_info}")
            
            # é æ¸¬
            predicted_label, confidence, all_probs = self.predict_single_sequence(sequence)
            predicted_class = self.label_encoder.classes_[predicted_label]
            
            # çµæœåˆ†æ
            is_correct = predicted_label == true_label
            if is_correct:
                correct_predictions += 1
            
            # é¡¯ç¤ºçµæœ
            print(f"ğŸ¯ çœŸå¯¦æ¨™ç±¤: {true_class}")
            print(f"ğŸ¤– é æ¸¬æ¨™ç±¤: {predicted_class}")
            print(f"ğŸ“Š é æ¸¬ä¿¡å¿ƒ: {confidence:.4f} ({confidence*100:.2f}%)")
            print(f"âœ… é æ¸¬çµæœ: {'æ­£ç¢º' if is_correct else 'éŒ¯èª¤'}")
            
            # é¡¯ç¤ºæ‰€æœ‰é¡åˆ¥çš„æ©Ÿç‡ï¼ˆå‰5åï¼‰
            prob_pairs = list(zip(self.label_encoder.classes_, all_probs))
            prob_pairs.sort(key=lambda x: x[1], reverse=True)
            
            print(f"\nğŸ“ˆ é æ¸¬æ©Ÿç‡æ’å (å‰5å):")
            for i, (class_name, prob) in enumerate(prob_pairs[:5]):
                marker = "ğŸ‘‘" if i == 0 else f"{i+1}."
                print(f"  {marker} {class_name}: {prob:.4f} ({prob*100:.2f}%)")
            
            print("-" * 50)
        
        # ç¸½çµ
        if num_tests > 0:
            accuracy = correct_predictions / num_tests
            print(f"\nğŸ† æ¸¬è©¦ç¸½çµ:")
            print(f"ç¸½æ¸¬è©¦æ¬¡æ•¸: {num_tests}")
            print(f"æ­£ç¢ºé æ¸¬: {correct_predictions}")
            print(f"æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
            
            if accuracy >= 0.8:
                print("ğŸŒŸ é€™æ‰¹éš¨æ©Ÿæ¨£æœ¬è¡¨ç¾å„ªç§€!")
            elif accuracy >= 0.6:
                print("ğŸ‘ é€™æ‰¹éš¨æ©Ÿæ¨£æœ¬è¡¨ç¾è‰¯å¥½!")
            else:
                print("ğŸ“ˆ é€™æ‰¹éš¨æ©Ÿæ¨£æœ¬é‚„æœ‰æ”¹é€²ç©ºé–“")
        
        print("=" * 70)

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ æ­¡è¿ä½¿ç”¨éš¨æ©Ÿå‹•ä½œæ¸¬è©¦å™¨!")
    
    try:
        tester = RandomActionTester()
        
        # å¯ä»¥èª¿æ•´é€™äº›åƒæ•¸
        print("è«‹è¼¸å…¥æ¸¬è©¦åƒæ•¸ï¼ˆç›´æ¥æŒ‰Enterä½¿ç”¨é è¨­å€¼ï¼‰:")
        num_tests_input = input("æ¸¬è©¦æ¬¡æ•¸ (é è¨­: 5): ").strip()
        num_tests = int(num_tests_input) if num_tests_input else 5
        
        sequence_length_input = input("åºåˆ—é•·åº¦ (é è¨­: 20): ").strip()
        sequence_length = int(sequence_length_input) if sequence_length_input else 20
        
        print(f"\né–‹å§‹é€²è¡Œ {num_tests} æ¬¡éš¨æ©Ÿæ¸¬è©¦...")
        tester.run_random_test(num_tests=num_tests, sequence_length=sequence_length)
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
    except Exception as e:
        print(f"æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

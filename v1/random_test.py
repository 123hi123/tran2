"""
éš¨æ©Ÿå‹•ä½œæ¸¬è©¦å™¨
éš¨æ©Ÿé¸æ“‡ä¸€å€‹æ‰‹èªå‹•ä½œï¼Œæ¸¬è©¦æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¢ºé æ¸¬
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import os
import random
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class SignLanguageGRU(nn.Module):
    """æ‰‹èªè¾¨è­˜GRUæ¨¡å‹ï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒçš„æ¶æ§‹ï¼‰"""
    
    def __init__(self, input_size, hidden_size=128, num_layers=2, num_classes=10, dropout=0.3):
        super(SignLanguageGRU, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # GRUå±¤
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=True
        )
        
        # å…¨é€£æ¥å±¤
        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)  # *2 å› ç‚ºé›™å‘GRU
        self.dropout = nn.Dropout(dropout)
        self.fc2 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # x shape: (batch_size, sequence_length, input_size)
        gru_out, _ = self.gru(x)
        
        # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥çš„è¼¸å‡º
        last_output = gru_out[:, -1, :]  # (batch_size, hidden_size * 2)
        
        # é€šéå…¨é€£æ¥å±¤
        out = self.fc1(last_output)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out

class RandomActionTester:
    def __init__(self, data_folder="v1/processed_data", model_folder="v1/models"):
        self.data_folder = data_folder
        self.model_folder = model_folder
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.label_encoder = None
        
        print(f"ğŸ¯ éš¨æ©Ÿå‹•ä½œæ¸¬è©¦å™¨å•Ÿå‹•")
        print(f"ä½¿ç”¨è¨­å‚™: {self.device}")
    
    def load_model(self, model_path=None):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if model_path is None:
            # æ‰¾æœ€æ–°çš„æ¨¡å‹
            model_files = [f for f in os.listdir(self.model_folder) if f.endswith('.pth')]
            if not model_files:
                raise FileNotFoundError("æ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æª”æ¡ˆ")
            model_path = os.path.join(self.model_folder, sorted(model_files)[-1])
        
        print(f"è¼‰å…¥æ¨¡å‹: {model_path}")
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # è¼‰å…¥æ¨™ç±¤ç·¨ç¢¼å™¨
        encoder_path = os.path.join(self.data_folder, "label_encoder.pkl")
        self.label_encoder = joblib.load(encoder_path)
        
        # å»ºç«‹æ¨¡å‹
        model_config = checkpoint['model_config']
        self.model = SignLanguageGRU(
            input_size=model_config['input_size'],
            hidden_size=model_config['hidden_size'],
            num_layers=model_config['num_layers'],
            num_classes=model_config['num_classes']
        ).to(self.device)
        
        # è¼‰å…¥æ¨¡å‹æ¬Šé‡
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        print(f"ğŸ“Š é¡åˆ¥æ•¸é‡: {len(self.label_encoder.classes_)}")
        print(f"ğŸ·ï¸ é¡åˆ¥: {list(self.label_encoder.classes_)}")
        
        return checkpoint
    
    def load_test_data(self):
        """è¼‰å…¥æ¸¬è©¦è³‡æ–™"""
        test_path = os.path.join(self.data_folder, "test_dataset.csv")
        
        if not os.path.exists(test_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¸¬è©¦è³‡æ–™é›†: {test_path}")
        
        test_data = pd.read_csv(test_path)
        print(f"ğŸ“ è¼‰å…¥æ¸¬è©¦è³‡æ–™: {test_data.shape}")
        
        # è™•ç†ç¼ºå¤±å€¼ï¼ˆèˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´ï¼‰
        self._preprocess_test_data(test_data)
        
        return test_data
    
    def _preprocess_test_data(self, data):
        """é è™•ç†æ¸¬è©¦æ•¸æ“šï¼Œç¢ºä¿èˆ‡è¨“ç·´æ™‚ä¸€è‡´"""
        total_missing = data.isnull().sum().sum()
        if total_missing > 0:
            print(f"âš ï¸  æ¸¬è©¦æ•¸æ“šç™¼ç¾ {total_missing} å€‹ç¼ºå¤±å€¼ï¼Œé€²è¡Œè™•ç†...")
            
            # å˜—è©¦ä½¿ç”¨æ”¹é€²çš„è™•ç†å™¨
            try:
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(__file__)))
                from improved_missing_handler import ImprovedMissingValueProcessor
                
                processor = ImprovedMissingValueProcessor()
                processor.calculate_neutral_positions(data)
                data_processed = processor.smart_interpolation(data)
                
                # å°‡è™•ç†çµæœæ›´æ–°å›åŸæ•¸æ“š
                data.update(data_processed)
                print("âœ… æ™ºèƒ½ç¼ºå¤±å€¼è™•ç†å®Œæˆ")
                
            except ImportError:
                print("âš ï¸  ä½¿ç”¨åŸºæœ¬ç¼ºå¤±å€¼è™•ç†...")
                # åŸºæœ¬çš„ç·šæ€§æ’å€¼
                numeric_columns = data.select_dtypes(include=[np.number]).columns
                for col in numeric_columns:
                    if data[col].isnull().any():
                        data[col] = data[col].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')
    
    def get_random_action_sequence(self, test_data, sequence_length=20):
        """éš¨æ©Ÿé¸æ“‡ä¸€å€‹å‹•ä½œçš„ä¸€å€‹åºåˆ—"""
        # ç²å–æ‰€æœ‰å¯ç”¨çš„é¡åˆ¥
        available_classes = test_data['sign_language'].unique()
        
        # éš¨æ©Ÿé¸æ“‡ä¸€å€‹é¡åˆ¥
        random_class = random.choice(available_classes)
        print(f"ğŸ² éš¨æ©Ÿé¸æ“‡çš„é¡åˆ¥: {random_class}")
        
        # ç²å–è©²é¡åˆ¥çš„æ‰€æœ‰æ•¸æ“š
        class_data = test_data[test_data['sign_language'] == random_class].copy()
        
        # æŒ‰source_videoåˆ†çµ„
        videos = class_data['source_video'].unique()
        random_video = random.choice(videos)
        print(f"ğŸ“¹ éš¨æ©Ÿé¸æ“‡çš„è¦–é »: {random_video}")
        
        # ç²å–è©²è¦–é »çš„æ•¸æ“š
        video_data = class_data[class_data['source_video'] == random_video].copy()
        video_data = video_data.sort_values('frame')
        
        # ç‰¹å¾µæ¬„ä½ï¼ˆ162ç¶­ï¼Œæ’é™¤frameï¼‰
        pose_columns = [f'pose_{i}' for i in range(36)]
        left_hand_columns = [f'left_hand_{i}' for i in range(63)]
        right_hand_columns = [f'right_hand_{i}' for i in range(63)]
        feature_columns = pose_columns + left_hand_columns + right_hand_columns
        
        # æª¢æŸ¥å¯ç”¨ç‰¹å¾µ
        available_features = [col for col in feature_columns if col in video_data.columns]
        
        if len(video_data) < sequence_length:
            print(f"âš ï¸  è¦–é »å¤ªçŸ­ ({len(video_data)} å¹€)ï¼Œéœ€è¦è‡³å°‘ {sequence_length} å¹€")
            return None, None, None, None
        
        # éš¨æ©Ÿé¸æ“‡åºåˆ—èµ·å§‹ä½ç½®
        max_start = len(video_data) - sequence_length
        random_start = random.randint(0, max_start)
        random_end = random_start + sequence_length
        
        print(f"ğŸ¬ é¸æ“‡åºåˆ—: ç¬¬ {random_start+1} - {random_end} å¹€")
        
        # æå–åºåˆ—
        sequence_data = video_data.iloc[random_start:random_end]
        features = sequence_data[available_features].values
        
        # æª¢æŸ¥åºåˆ—å®Œæ•´æ€§
        if np.isnan(features).all():
            print("âš ï¸  åºåˆ—å…¨ç‚ºç¼ºå¤±å€¼ï¼Œé‡æ–°é¸æ“‡...")
            return self.get_random_action_sequence(test_data, sequence_length)
        
        # æ¨™ç±¤ç·¨ç¢¼
        true_label = self.label_encoder.transform([random_class])[0]
        
        return features, true_label, random_class, f"{random_video}[{random_start+1}:{random_end}]"
    
    def predict_single_sequence(self, sequence):
        """å°å–®å€‹åºåˆ—é€²è¡Œé æ¸¬"""
        # è½‰æ›ç‚ºtensorä¸¦æ·»åŠ batchç¶­åº¦
        sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(self.device)  # (1, seq_len, features)
        
        # é æ¸¬
        with torch.no_grad():
            outputs = self.model(sequence_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(outputs, dim=1).item()
            confidence = probabilities[0, predicted_class].item()
        
        return predicted_class, confidence, probabilities[0].cpu().numpy()
    
    def run_random_test(self, num_tests=1, sequence_length=20):
        """åŸ·è¡Œéš¨æ©Ÿæ¸¬è©¦"""
        print("=" * 70)
        print("ğŸ¯ éš¨æ©Ÿå‹•ä½œé æ¸¬æ¸¬è©¦")
        print("=" * 70)
        
        # è¼‰å…¥æ¨¡å‹å’Œæ•¸æ“š
        self.load_model()
        test_data = self.load_test_data()
        
        correct_predictions = 0
        
        for test_num in range(num_tests):
            print(f"\nğŸ”„ æ¸¬è©¦ {test_num + 1}/{num_tests}")
            print("-" * 50)
            
            # ç²å–éš¨æ©Ÿåºåˆ—
            sequence, true_label, true_class, sequence_info = self.get_random_action_sequence(
                test_data, sequence_length
            )
            
            if sequence is None:
                print("è·³éæ­¤æ¬¡æ¸¬è©¦...")
                continue
            
            # é æ¸¬
            predicted_label, confidence, all_probs = self.predict_single_sequence(sequence)
            predicted_class = self.label_encoder.classes_[predicted_label]
            
            # çµæœåˆ†æ
            is_correct = predicted_label == true_label
            if is_correct:
                correct_predictions += 1
            
            # é¡¯ç¤ºçµæœ
            print(f"ğŸ“ åºåˆ—ä¾†æº: {sequence_info}")
            print(f"ğŸ¯ çœŸå¯¦æ¨™ç±¤: {true_class}")
            print(f"ğŸ¤– é æ¸¬æ¨™ç±¤: {predicted_class}")
            print(f"ğŸ“Š é æ¸¬ä¿¡å¿ƒ: {confidence:.4f} ({confidence*100:.2f}%)")
            print(f"âœ… é æ¸¬çµæœ: {'æ­£ç¢º' if is_correct else 'éŒ¯èª¤'}")
            
            # é¡¯ç¤ºæ‰€æœ‰é¡åˆ¥çš„æ©Ÿç‡ï¼ˆå‰5åï¼‰
            prob_pairs = list(zip(self.label_encoder.classes_, all_probs))
            prob_pairs.sort(key=lambda x: x[1], reverse=True)
            
            print(f"\nğŸ“ˆ é æ¸¬æ©Ÿç‡æ’å (å‰5å):")
            for i, (class_name, prob) in enumerate(prob_pairs[:5]):
                marker = "ğŸ‘‘" if i == 0 else f"{i+1}."
                print(f"  {marker} {class_name}: {prob:.4f} ({prob*100:.2f}%)")
            
            print("-" * 50)
        
        # ç¸½çµ
        if num_tests > 0:
            accuracy = correct_predictions / num_tests
            print(f"\nğŸ† æ¸¬è©¦ç¸½çµ:")
            print(f"ç¸½æ¸¬è©¦æ¬¡æ•¸: {num_tests}")
            print(f"æ­£ç¢ºé æ¸¬: {correct_predictions}")
            print(f"æº–ç¢ºç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        print("=" * 70)

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ æ­¡è¿ä½¿ç”¨éš¨æ©Ÿå‹•ä½œæ¸¬è©¦å™¨!")
    
    try:
        tester = RandomActionTester()
        
        # å¯ä»¥èª¿æ•´é€™äº›åƒæ•¸
        num_tests = int(input("è«‹è¼¸å…¥æ¸¬è©¦æ¬¡æ•¸ (é è¨­: 5): ") or "5")
        sequence_length = int(input("è«‹è¼¸å…¥åºåˆ—é•·åº¦ (é è¨­: 20): ") or "20")
        
        print(f"\né–‹å§‹é€²è¡Œ {num_tests} æ¬¡éš¨æ©Ÿæ¸¬è©¦...")
        tester.run_random_test(num_tests=num_tests, sequence_length=sequence_length)
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ¶ä¸­æ–·æ¸¬è©¦")
    except Exception as e:
        print(f"æ¸¬è©¦éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()

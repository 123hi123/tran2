"""
å¿«é€Ÿéš¨æ©Ÿæ¸¬è©¦
ç›´æ¥é‹è¡Œï¼Œéš¨æ©Ÿé¸æ“‡5å€‹å‹•ä½œæ¸¬è©¦æ¨¡å‹é æ¸¬èƒ½åŠ›
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import joblib
import os
import random
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œè®“çµæœå¯é‡ç¾ï¼ˆå¦‚æœæƒ³è¦å®Œå…¨éš¨æ©Ÿï¼Œå¯ä»¥è¨»è§£æ‰é€™è¡Œï¼‰
random.seed(42)
np.random.seed(42)
torch.manual_seed(42)

class SignLanguageGRU(nn.Module):
    """æ‰‹èªè¾¨è­˜GRUæ¨¡å‹"""
    
    def __init__(self, input_size, hidden_size=128, num_layers=2, num_classes=10, dropout=0.3):
        super(SignLanguageGRU, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.gru = nn.GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0,
            bidirectional=True
        )
        
        self.fc1 = nn.Linear(hidden_size * 2, hidden_size)
        self.dropout = nn.Dropout(dropout)
        self.fc2 = nn.Linear(hidden_size, num_classes)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        gru_out, _ = self.gru(x)
        last_output = gru_out[:, -1, :]
        
        out = self.fc1(last_output)
        out = self.relu(out)
        out = self.dropout(out)
        out = self.fc2(out)
        
        return out

def load_model_and_data():
    """è¼‰å…¥æ¨¡å‹å’Œæ•¸æ“š"""
    data_folder = "v1/processed_data"
    model_folder = "v1/models"
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {device}")
    
    # æ‰¾æœ€æ–°æ¨¡å‹
    model_files = [f for f in os.listdir(model_folder) if f.endswith('.pth')]
    if not model_files:
        raise FileNotFoundError("æ‰¾ä¸åˆ°ä»»ä½•æ¨¡å‹æª”æ¡ˆ")
    
    model_path = os.path.join(model_folder, sorted(model_files)[-1])
    print(f"ğŸ“ è¼‰å…¥æ¨¡å‹: {model_path}")
    
    # è¼‰å…¥æ¨¡å‹
    checkpoint = torch.load(model_path, map_location=device)
    
    # è¼‰å…¥æ¨™ç±¤ç·¨ç¢¼å™¨
    encoder_path = os.path.join(data_folder, "label_encoder.pkl")
    label_encoder = joblib.load(encoder_path)
    
    # å»ºç«‹æ¨¡å‹
    model_config = checkpoint['model_config']
    model = SignLanguageGRU(
        input_size=model_config['input_size'],
        hidden_size=model_config['hidden_size'],
        num_layers=model_config['num_layers'],
        num_classes=model_config['num_classes']
    ).to(device)
    
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # è¼‰å…¥æ¸¬è©¦æ•¸æ“š
    test_path = os.path.join(data_folder, "test_dataset.csv")
    test_data = pd.read_csv(test_path)
    
    print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼Œé¡åˆ¥: {list(label_encoder.classes_)}")
    print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“š: {test_data.shape}")
    
    return model, label_encoder, test_data, device

def get_random_sequence(test_data, label_encoder, sequence_length=20):
    """ç²å–éš¨æ©Ÿåºåˆ—"""
    # éš¨æ©Ÿé¸æ“‡é¡åˆ¥
    available_classes = test_data['sign_language'].unique()
    random_class = random.choice(available_classes)
    
    # ç²å–è©²é¡åˆ¥æ•¸æ“š
    class_data = test_data[test_data['sign_language'] == random_class].copy()
    
    # éš¨æ©Ÿé¸æ“‡è¦–é »
    videos = class_data['source_video'].unique()
    random_video = random.choice(videos)
    
    # ç²å–è¦–é »æ•¸æ“š
    video_data = class_data[class_data['source_video'] == random_video].copy()
    video_data = video_data.sort_values('frame')
    
    if len(video_data) < sequence_length:
        return get_random_sequence(test_data, label_encoder, sequence_length)
    
    # ç‰¹å¾µæ¬„ä½
    pose_columns = [f'pose_{i}' for i in range(36)]
    left_hand_columns = [f'left_hand_{i}' for i in range(63)]
    right_hand_columns = [f'right_hand_{i}' for i in range(63)]
    feature_columns = pose_columns + left_hand_columns + right_hand_columns
    available_features = [col for col in feature_columns if col in video_data.columns]
    
    # éš¨æ©Ÿé¸æ“‡åºåˆ—ä½ç½®
    max_start = len(video_data) - sequence_length
    random_start = random.randint(0, max_start)
    random_end = random_start + sequence_length
    
    # æå–åºåˆ—
    sequence_data = video_data.iloc[random_start:random_end]
    features = sequence_data[available_features].values
    
    # è™•ç†ç¼ºå¤±å€¼
    if np.isnan(features).any():
        # ç°¡å–®ç·šæ€§æ’å€¼
        for i in range(features.shape[1]):
            col_data = features[:, i]
            if np.isnan(col_data).any():
                # å‰å‘å¡«å……ç„¶å¾Œå¾Œå‘å¡«å……
                mask = ~np.isnan(col_data)
                if mask.any():
                    features[:, i] = np.interp(
                        np.arange(len(col_data)),
                        np.arange(len(col_data))[mask],
                        col_data[mask]
                    )
                else:
                    features[:, i] = 0  # å¦‚æœå…¨æ˜¯NaNï¼Œå¡«å……ç‚º0
    
    true_label = label_encoder.transform([random_class])[0]
    sequence_info = f"{random_video}[{random_start+1}:{random_end}]"
    
    return features, true_label, random_class, sequence_info

def predict_sequence(model, sequence, device):
    """é æ¸¬åºåˆ—"""
    sequence_tensor = torch.FloatTensor(sequence).unsqueeze(0).to(device)
    
    with torch.no_grad():
        outputs = model(sequence_tensor)
        probabilities = torch.softmax(outputs, dim=1)
        predicted_class = torch.argmax(outputs, dim=1).item()
        confidence = probabilities[0, predicted_class].item()
    
    return predicted_class, confidence, probabilities[0].cpu().numpy()

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ å¿«é€Ÿéš¨æ©Ÿå‹•ä½œé æ¸¬æ¸¬è©¦")
    print("=" * 60)
    
    try:
        # è¼‰å…¥æ¨¡å‹å’Œæ•¸æ“š
        model, label_encoder, test_data, device = load_model_and_data()
        
        # é€²è¡Œ5æ¬¡éš¨æ©Ÿæ¸¬è©¦
        num_tests = 5
        correct_predictions = 0
        
        for i in range(num_tests):
            print(f"\nğŸ² ç¬¬ {i+1} æ¬¡éš¨æ©Ÿæ¸¬è©¦")
            print("-" * 40)
            
            # ç²å–éš¨æ©Ÿåºåˆ—
            sequence, true_label, true_class, sequence_info = get_random_sequence(
                test_data, label_encoder
            )
            
            # é æ¸¬
            predicted_label, confidence, all_probs = predict_sequence(model, sequence, device)
            predicted_class = label_encoder.classes_[predicted_label]
            
            # çµæœ
            is_correct = predicted_label == true_label
            if is_correct:
                correct_predictions += 1
            
            # é¡¯ç¤ºçµæœ
            print(f"ğŸ“ åºåˆ—ä¾†æº: {sequence_info}")
            print(f"ğŸ¯ å¯¦éš›å‹•ä½œ: {true_class}")
            print(f"ğŸ¤– é æ¸¬å‹•ä½œ: {predicted_class}")
            print(f"ğŸ“Š é æ¸¬ä¿¡å¿ƒ: {confidence:.4f} ({confidence*100:.1f}%)")
            
            if is_correct:
                print("âœ… é æ¸¬æ­£ç¢º! ğŸ‰")
            else:
                print("âŒ é æ¸¬éŒ¯èª¤...")
                
                # é¡¯ç¤ºå‰3åé æ¸¬
                prob_pairs = list(zip(label_encoder.classes_, all_probs))
                prob_pairs.sort(key=lambda x: x[1], reverse=True)
                print("å‰3åé æ¸¬:")
                for j, (class_name, prob) in enumerate(prob_pairs[:3]):
                    print(f"  {j+1}. {class_name}: {prob:.3f} ({prob*100:.1f}%)")
        
        # ç¸½çµ
        accuracy = correct_predictions / num_tests
        print(f"\nğŸ† æ¸¬è©¦ç¸½çµ")
        print("=" * 40)
        print(f"ç¸½æ¸¬è©¦æ¬¡æ•¸: {num_tests}")
        print(f"æ­£ç¢ºé æ¸¬: {correct_predictions}")
        print(f"é æ¸¬æº–ç¢ºç‡: {accuracy:.3f} ({accuracy*100:.1f}%)")
        
        if accuracy >= 0.8:
            print("ğŸŒŸ æ¨¡å‹è¡¨ç¾å„ªç§€!")
        elif accuracy >= 0.6:
            print("ğŸ‘ æ¨¡å‹è¡¨ç¾è‰¯å¥½!")
        else:
            print("ğŸ“ˆ æ¨¡å‹é‚„æœ‰æ”¹é€²ç©ºé–“")
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
